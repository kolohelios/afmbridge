import Vapor

/// Response structure for OpenAI-compatible chat completions endpoint
public struct ChatCompletionResponse: Content {
    /// Unique identifier for this completion
    public let id: String

    /// Object type (always "chat.completion")
    public let object: String

    /// Unix timestamp of when the completion was created
    public let created: Int

    /// The model used for completion
    public let model: String

    /// List of completion choices
    public let choices: [Choice]

    public init(id: String, object: String, created: Int, model: String, choices: [Choice]) {
        self.id = id
        self.object = object
        self.created = created
        self.model = model
        self.choices = choices
    }

    /// A completion choice returned by the model
    public struct Choice: Codable, Sendable {
        /// Index of this choice in the list
        public let index: Int

        /// The message generated by the model
        public let message: ChatMessage

        /// Reason the model stopped generating tokens
        public let finishReason: String?

        public init(index: Int, message: ChatMessage, finishReason: String?) {
            self.index = index
            self.message = message
            self.finishReason = finishReason
        }

        enum CodingKeys: String, CodingKey {
            case index
            case message
            case finishReason = "finish_reason"
        }
    }
}
